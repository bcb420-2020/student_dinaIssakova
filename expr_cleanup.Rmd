---
title: "KCvsKR Dataset Cleanup"
output:
  html_document:
    df_print: paged
---

This dataset explores the factors contributing to keratoconus (KTCN). Keratoconus is a disorder of the eye that results in progressive thinning of the cornea, which may result in blurry vision, double vision, nearsightedness, astigmatism, and light sensitivity. This study performed comprehensive transcriptome profiling of human KTCN corneas using an RNA-Seq approach, the discovery analysis comparing eight KTCN (test condition) and eight non-KTCN (control) corneas.

This dataset was of interest to me given the complexity of disorders associated with vision. In the past, I have worked on research detailing the evolution of light sensitivity and specific proteins in mammalian lineages; as such, I was interested in seeing how the transcriptome can be affected in a cornea disease, and how that fits in with my existing knowledge on the subject.


First we install any necessary packages.

```{r}
if (!require(BiocManager)){
  install.packages("BiocManager")
}
if (!require(GEOmetadb)){
  BiocManager::install("GEOmetadb")
}
if (!require(biomaRt)){
  BiocManager::install("biomaRt")
}
if (!require(dplyr)){
  install.packages("dplyr")
}
if (!require(edgeR)){
  BiocManager::install("edgeR")
}

```


First we download the dataset, if it isn't already downloaded.

```{r}
library(GEOmetadb)
if (!exists("sfiles")){
  sfiles = getGEOSuppFiles('GSE77938')
  # the second file is the discovery gene counts, contrary to the transcript counts or the replication data.
  discoveryCounts = read.delim(rownames(sfiles)[2],header=TRUE)
  head(discoveryCounts)
}
```

Compute overview statistics to assess data quality for the control and test conditions in your dataset.

```{r}

dim(discoveryCounts)


```

We then map to HUGO identifiers. We will map it manually through biomaRt, and check if all the gene symbols are actually correct HGNC symbols rather than aliases. This will also find any missing values. 

```{r}


library(biomaRt)
library(dplyr)

conversion_stash <- "discounts_id_conversion.rds"
if(file.exists(conversion_stash)){
  discounts_id_conversion <- readRDS(conversion_stash)
} else {
  ensembl <- useMart("ensembl")
  ensembl = useDataset("hsapiens_gene_ensembl",mart=ensembl)
  discounts_id_conversion <- getBM(attributes = c("ensembl_gene_id","hgnc_symbol"),
                            filters = c("ensembl_gene_id"),
                            values = discoveryCounts$GeneID,
                            mart = ensembl)
  saveRDS(discounts_id_conversion, conversion_stash)
}

names(discoveryCounts)[names(discoveryCounts) == "GeneID"] <- "ensembl_gene_id"


discoveryCountsMapped <- dplyr::left_join(discoveryCounts, discounts_id_conversion, by=c("ensembl_gene_id"))

```

We can check if there are any duplicates with gene counts, and then verify later with duplicated ().

```{r}


summarized_gene_counts <- sort(table(discoveryCounts$ensembl_gene_id),decreasing = TRUE)
summarized_gene_counts[which(summarized_gene_counts>1)[1:10]]

```


First, we omit those that aren't mapped to an HUGO symbol name.

```{r}
length(which(is.na(discoveryCountsMapped$hgnc_symbol)))
discoveryCountsClean <- discoveryCountsMapped[which(!is.na(discoveryCountsMapped$hgnc_symbol)),]

```

4004 genes were omitted this way.

Next we check for multiple ensembl ID's that map to the same HUGO symbol. 

```{r}
discoveryCountsClean <- discoveryCountsMapped[which(!is.na(discoveryCountsMapped$hgnc_symbol)),]

length((discoveryCountsClean$ensembl_gene_id)) - length(unique(discoveryCountsClean$ensembl_gene_id))
```

There are three ensembl gene ID's that are duplicated. 

```{r}
duplist <- discoveryCountsClean[duplicated(discoveryCountsClean$ensembl_gene_id),]
duplist

discoveryCountsClean[which(discoveryCountsClean$ensembl_gene_id%in%duplist$ensembl_gene_id),]

```

We can see that this is the same ensembl gene ID mapped to different hgnc symbols. These are likely outdated aliases of current symbols, or possibly deprecated ORFs. Because there are so few of these, we can look them up manually. 

C12orf74 is a depreciated ORF, and so PLEKHG7 should be kept. 
LINC00595 is the correct current symbol, and LINC00856 is outdated. 
CCL3L3 is the correct current symbol, and CCL3L1 is outdated. 

Note that the values are the same for each pair of rows, and thus this manipulation doesn't impact our data. These don't count as removed genes.

```{r}
discoveryCountsClean <- discoveryCountsClean[!(discoveryCountsClean$hgnc_symbol%in%c("C12orf74", "LINC00856", "CCL3L1")),]
discoveryCountsClean[which(discoveryCountsClean$ensembl_gene_id%in%duplist$ensembl_gene_id),]
```

Now we can make the same analysis to find more than one ensembl ID mapped to the same hgnc_symbol. 

```{r}
duphgnc <- discoveryCountsClean[duplicated(discoveryCountsClean$hgnc_symbol),]
duphgnc
length(duphgnc)
```
A lot of these are marked to a 'blank' HGNC symbol. We can remove these. 18 genes are removed this way.

```{r}
discoveryCountsClean <- discoveryCountsClean[which(!(discoveryCountsClean$hgnc_symbol == "")),]
duphgnc <- discoveryCountsClean[duplicated(discoveryCountsClean$hgnc_symbol),]
duphgnc
```

There are 13 duplicate rows. These could be splice variants, or probes that are designed as internal controls. Do they have the same data? 

```{r}
discoveryCountsClean[which(discoveryCountsClean$hgnc_symbol%in%duphgnc$hgnc_symbol),]
```

Unlike the ensembl ID's, these don't have the same data. As such deleting them might influence our data. Instead we'll append version ID's to the HGNC symbols to be able to separate them and have unique HGNC symbols. 

```{r}
discoveryCountsClean[duplicated(discoveryCountsClean$hgnc_symbol),]$hgnc_symbol <- 
  paste(discoveryCountsClean[duplicated(discoveryCountsClean$hgnc_symbol),]$hgnc_symbol, ".2")
```

Now we have no more duplicates in our data: 
```{r}
length((discoveryCountsClean$ensembl_gene_id)) - length(unique(discoveryCountsClean$ensembl_gene_id))
length((discoveryCountsClean$hgnc_symbol)) - length(unique(discoveryCountsClean$hgnc_symbol))
```

A total of 4022 genes have been removed so far. 

So now we can assign rownames to our data. 

```{r}
rownames(discoveryCountsClean) <- discoveryCountsClean$hgnc_symbol
```

Now, we have dealt with repeating mappings in both directions and removed any unmapped outliers. We proceed to normalizing the dataset. In edgeR, it is recommended to remove features without at least 1 read per million in n of the samples, where n is the size of the smallest group of replicates. There are 16 samples in the group, so n = 16.

```{r}
cpms = cpm(discoveryCountsClean[,2:17])
rownames(cpms) <- discoveryCountsClean[,1]
# get rid of low counts
keep = rowSums(cpms >1) >=3
discoveryCountsFiltered = discoveryCountsClean[keep,]
discoveryCountsOutliers = discoveryCountsClean[!keep,]
nrow(discoveryCountsFiltered)
nrow(discoveryCountsOutliers)
```

As such we've removed 21 428 outliers due to low counts.
What does this do to the data? 
```{r}
dim(discoveryCountsFiltered)
```

The final coverage of our dataset is 15 810 genes.
We have a lot less genes covered now, but the dataset is of better quality.

```{r}

data2plot <- log2(edgeR::cpm(discoveryCountsFiltered[,2:17]))
boxplot(data2plot, xlab = "Samples", ylab = "log2 CPM", 
        las = 2, cex = 0.5, cex.lab = 0.5,
        cex.axis = 0.5, main = "KRvsKC RNASeq Samples")

```
 
 Observe the data distribution by a density plot: 
 
```{r}
counts_density <- apply(log2(cpm(discoveryCountsFiltered[,2:17])), 2, density)
  #calculate the limits across all the samples
    xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x)); 
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
         ylab="Smoothing density of log2-CPM", main="KCvsKR Data Before Normalization", cex.lab = 0.85)
    #plot each line
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(data2plot),  
           col=cols, lty=ltys, cex=0.75, 
           border ="blue",  text.col = "green4", 
           merge = TRUE, bg = "gray90")
```
 
 As this is RNASeq data, for normalization we will apply Trimmed Mean of M-Values, or TMM. First we define the groups we want to divide by.
 
```{r}
samples <- data.frame(lapply(colnames(discoveryCountsFiltered)[2:17], 
        FUN=function(x){unlist(strsplit(x, split = "_"))[c(1,2)]}))
colnames(samples) <- colnames(discoveryCountsFiltered)[2:17]
rownames(samples) <- c("cell_type","sample_num")
samples <- data.frame(t(samples))
```
 
 Then we apply the normalisation.

```{r}

  
filtered_data_matrix <- as.matrix(discoveryCountsFiltered[,2:17])
rownames(filtered_data_matrix) <- discoveryCountsFiltered$hgnc_symbol
d = DGEList(counts=filtered_data_matrix, group=samples$cell_type)

d = calcNormFactors(d)

normalized_counts <- cpm(d)


```
 
Compare before and after of both plots. 
 
```{r}


counts_density <- apply(log2(cpm(normalized_counts)), 2, density)
  #calculate the limits across all the samples
    xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x)); 
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n", 
         ylab="Smoothing density of log2-CPM", main="KCvsKR Data After Normalization", cex.lab = 0.85)
    #plot each line
    for (i in 1:length(counts_density)) lines(counts_density[[i]], col=cols[i], lty=ltys[i])
    #create legend
    legend("topright", colnames(data2plot),  
           col=cols, lty=ltys, cex=0.75, 
           border ="blue",  text.col = "green4", 
           merge = TRUE, bg = "gray90")


```
 
 
 The distribution of our data didn't change significantly, which is good - we want to only remove slight technical variation, not biological variation. 

What are the overall metrics of our data? 


MDS: 

```{r}
plotMDS(d, labels=rownames(samples),
  col = c("darkgreen","blue")[factor(samples$cell_type)])
```


The conditions themselves seem to cluster the most; there isn't much clustering between different conditions implying an inherent similarity in a sample or a bias. 

Estimating common and tagwise dispersion doesn't seem to be entirely possible, because the samples for the two conditions are separately numbered in the discovery gene counts. To properly do this, we need to invoke the replicate count matrix. As such, this is omitted in this data preparation. 

Code for normalization and data analysis of the dataset is mostly taken from BCB420 course materials. 

Final dataset: 

```{r}
head(normalized_counts)
```

